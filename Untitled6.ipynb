{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqBsUQWUahr1UiC50+R0ny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthika-Sekar-2006/DataSciene-DataVisualization-/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUv8mxk6Y4sB",
        "outputId": "ad979e1d-edb4-4647-cdd0-f55f97b8e826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      comments  \\\n",
            "0           I love this product! It's amazing.   \n",
            "1  This is the worst experience I've ever had.   \n",
            "2          I'm not sure how I feel about this.   \n",
            "3   Absolutely fantastic! Highly recommend it.   \n",
            "4         I hate waiting for customer service.   \n",
            "\n",
            "                                    sentiment_scores sentiment  \n",
            "0  {'neg': 0.0, 'neu': 0.266, 'pos': 0.734, 'comp...  positive  \n",
            "1  {'neg': 0.369, 'neu': 0.631, 'pos': 0.0, 'comp...  negative  \n",
            "2  {'neg': 0.246, 'neu': 0.754, 'pos': 0.0, 'comp...  negative  \n",
            "3  {'neg': 0.0, 'neu': 0.293, 'pos': 0.707, 'comp...  positive  \n",
            "4  {'neg': 0.481, 'neu': 0.519, 'pos': 0.0, 'comp...  negative  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "data = {\n",
        "    'comments': [\n",
        "        \"I love this product! It's amazing.\",\n",
        "        \"This is the worst experience I've ever had.\",\n",
        "        \"I'm not sure how I feel about this.\",\n",
        "        \"Absolutely fantastic! Highly recommend it.\",\n",
        "        \"I hate waiting for customer service.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "def analyze_sentiment(comment):\n",
        "    scores = sid.polarity_scores(comment)\n",
        "    return scores\n",
        "df['sentiment_scores'] = df['comments'].apply(analyze_sentiment)\n",
        "df['compound'] = df['sentiment_scores'].apply(lambda x: x['compound'])\n",
        "df['sentiment'] = df['compound'].apply(lambda x: 'positive' if x > 0.05 else ('negative' if x < -0.05 else 'neutral'))\n",
        "print(df[['comments', 'sentiment_scores', 'sentiment']])"
      ]
    }
  ]
}